# 1.1 AI 基础认知

在正式聊AI工具之前，我们得先把几个基本概念理清楚。不然后面遇到什么"大模型"、"Token"、"上下文窗口"这些词，你只能点头装懂，心里其实一团浆糊。

## AI、机器学习、深度学习：三层套娃

这三个词经常被混着用，但它们其实是一个包含关系，像俄罗斯套娃一样一层套一层。

**人工智能（AI）** 是最大的那个圈。只要是让机器表现出某种"智能"的技术，都算AI。最早的AI其实很笨，就是一堆if-else规则——如果温度超过30度，就开空调。这也叫AI，只不过是最原始的那种。

**机器学习（ML）** 是AI里面的一个子集。它的核心思路是：别写规则了，让机器自己从数据里学规则。你给它一万张猫的照片和一万张狗的照片，它自己琢磨出猫和狗的区别。比人写规则聪明多了，因为你让人总结"猫和狗到底哪里不同"，人也说不太清楚。

**深度学习（DL）** 是机器学习里面的一个子集。它用的工具叫"神经网络"，灵感来自人脑的神经元连接方式。"深度"指的是神经网络的层数很多，层数越多，能学到的模式就越复杂。今天我们聊的所有大模型，本质上都是深度学习。

所以关系很简单：**AI > 机器学习 > 深度学习 > 大语言模型**。

## 大语言模型：为什么AI能"说人话"

ChatGPT背后的技术叫大语言模型（Large Language Model，简称LLM）。它能跟你自然对话，写文章、写代码、做翻译，看起来好像真的"懂"语言。

但它的底层原理其实出乎意料地简单——**预测下一个词**。

你输入"今天天气真"，模型会计算接下来每个词出现的概率："好"80%、"差"10%、"热"5%……然后大概率选"好"。接着再预测"好"后面是什么，如此循环，一个字一个字地生成回答。

这就引出了几个关键概念：

**Token（词元）。** 模型不是按"字"或"词"来处理文本的，而是按Token。你可以粗略地理解为，中文里一个汉字大约是1-2个Token，英文里一个单词大约是1-3个Token。为什么要知道这个？因为模型的收费、输入长度限制，都是按Token算的。

**Transformer（变换器）。** 这是2017年Google提出的一个架构，也是几乎所有大语言模型的底座。它最厉害的地方是"注意力机制"——模型在预测下一个词的时候，能同时"关注"到输入中所有位置的信息，而不是只看最近的几个词。比如你说"小明去年在北京上大学，他今年毕业了，准备回老家找工作"，模型能把"他"和前面的"小明"关联起来。这在以前的技术里是很难做到的。

**上下文窗口（Context Window）。** 这是模型一次能"看到"的文本长度上限。比如一个模型的上下文窗口是128K Token，那你跟它的对话加起来超过这个长度，它就会"忘掉"最早的内容。这就是为什么有时候聊着聊着，AI好像忘了你前面说过的话。

**Temperature（温度）。** 这个参数控制模型输出的"随机性"。Temperature越低（比如0），模型越倾向于选概率最高的词，输出更稳定、更可预测；Temperature越高（比如1），模型会更大胆地选一些低概率的词，输出更有创意但也更不可控。写代码的时候你希望Temperature低一点，写诗的时候可以高一点。

## AI能做什么，不能做什么

搞清楚AI的能力边界特别重要，不然你要么低估它、要么高估它，都会影响你的使用效果。

**AI擅长的事情：** 文本生成和改写（写邮件、润色文档、翻译）、信息提取和整理（从长文中总结要点）、代码编写和调试、创意发散（头脑风暴、起名字）、格式化转换（把文字变表格、把数据变图表描述）。这些任务的共同特点是：有大量的训练数据可以学习，而且不需要"绝对正确"。

**AI不擅长的事情：** 精确的数学计算（它可能会算错8547 x 2361）、实时信息查询（它的知识有截止日期）、需要真实世界经验的判断（比如"这个方案客户会不会买账"）、长程逻辑推理（特别复杂的多步推理容易出错）、以及任何需要"保证100%正确"的场景。

## 主流模型认知

目前市面上的大模型可以分两个阵营：闭源商业模型和开源模型。

**闭源商业模型：**

这些模型由资金雄厚的巨头维护，性能通常领先 3-6 个月，且拥有最完善的云端生态。

- **GPT系列（OpenAI）：** 最新型号： GPT-5 / GPT-5.3-Codex
  - 核心特性： 2026 年的主力是 GPT-5，它实现了真正的“全时记忆（Persistent Memory）”。新发布的 GPT-5.3-Codex 已成为 GitHub Copilot 的核心，它不再只是写代码，而是能自主完成“从需求分析到部署上线”的闭环任务。其 o1/o3 推理系列已集成进默认模式，具备人类级别的逻辑推演能力。
- **Claude系列（Anthropic）：** 最新型号： Claude 4.6 / Opus 4.6（2026 年 2 月发布）。
  - 核心特性： 在“Computer Use”（计算机控制工具）领域保持统治地位。它能像人类一样操作网页和桌面应用，处理复杂的企业流程。Claude 4.6 在消除幻觉和精准遵循长达 100 页的指令方面，编程王者。
- **Gemini系列（Google）：** 最新型号： Gemini 3 Pro / Flash。
  - 核心特性： 2026 年全面普及了 “个人智能（Personal Intelligence）”，通过与 Gmail、Google Photos、Drive 的深度原生连接，它能处理极其个性化的任务。上下文窗口已稳定在 200 万至 500 万 Token 级别，支持分钟级的超长视频即时分析。

**开源模型：**

开源阵营通过高效的架构设计（如 MoE）极大地缩小了与闭源模型的差距，并在私有化部署上占据优势。

- **Llama系列（Meta）：** 最新型号： Llama 4 系列（2025 年底升级）。
  - 核心特性： Llama 4 引入了原生多模态支持（同时处理图、音、文），并极大增强了在移动端硬件上的运行效率。虽然 Meta 内部已开始研发更强的闭源代号“Avocado”，但 Llama 4 依然是全球开源社区的灵魂。
- **Qwen系列（阿里）：** 最新型号： Qwen-3.0 / Qwen-Image-2.0。
  - 核心特性： 在中文语境下的理解力和文化适应性保持领先。2026 年新发布的 Qwen-Image-2.0 实现了极强的文字渲染能力，能够直接生成带精确排版的 PPT 页面和复杂信息图表，极大赋能了办公场景。
- **DeepSeek系列：** 最新进展： DeepSeek-V3 / MODEL1 架构。
  - 核心特性： 2026 年，DeepSeek 凭借超高的计算效率（MoE 混合专家模型）震撼业界，在推理成本仅为 GPT-4o 几分之一的情况下，性能实现了对标。它是目前开发者进行国产化替代和高性价比 API 调用时的首选。

**模型参数量** 是经常被提到的一个指标，比如"7B"就是70亿参数，"70B"就是700亿参数。参数量越大，模型理论上越"聪明"，但也越耗资源。不过参数量不是唯一指标，训练数据质量、训练方法同样重要，参数小的模型也完全可能在某些任务上超过参数大的模型。

对于大部分人来说，不需要纠结"哪个模型最好"。不同模型各有长处，实际使用中多试几个、根据自己的场景选就行。后面在AI工具全景图那一章，我们会更具体地聊怎么选。
