# 4.3 AI应用开发基础

前面两节聊的是"用AI帮你写代码"，从这节开始我们聊另一个话题：**怎么写代码来调用AI**。你的产品里要接入AI能力——比如做一个智能客服、做一个文档问答系统、做一个代码审查工具——第一步就是学会调LLM的API。

## LLM API接入

不管是Anthropic、OpenAI还是国产模型，API的调用模式都高度相似。你发一个HTTP请求，带上你的对话消息，模型返回一个回复。核心就这么简单。

先看Anthropic（Claude）的API调用：

```python
from anthropic import Anthropic

client = Anthropic(api_key="sk-ant-xxx")

message = client.messages.create(
    model="claude-sonnet-4-5-20250929",
    max_tokens=1024,
    system="你是一个代码审查助手",
    messages=[
        {"role": "user", "content": "请审查以下代码：\ndef add(a, b): return a + b"}
    ]
)
print(message.content[0].text)
```

Anthropic的API设计有个特点：system prompt是独立参数，不放在messages数组里，这在逻辑上更清晰。2026年最新的模型ID：Opus 4.6是`claude-opus-4-6`，Sonnet 4.5是`claude-sonnet-4-5-20250929`。Opus 4.6支持100万Token的上下文窗口。

OpenAI的API风格略有不同：

```python
from openai import OpenAI

client = OpenAI(api_key="sk-xxx")

response = client.chat.completions.create(
    model="gpt-4o",
    messages=[
        {"role": "system", "content": "你是一个代码审查助手"},
        {"role": "user", "content": "请审查以下代码：\ndef add(a, b): return a + b"}
    ],
    temperature=0.3
)
print(response.choices[0].message.content)
```

TypeScript侧，以Anthropic为例：

```typescript
import Anthropic from "@anthropic-ai/sdk";

const client = new Anthropic({ apiKey: "sk-ant-xxx" });

const message = await client.messages.create({
  model: "claude-sonnet-4-5-20250929",
  max_tokens: 1024,
  system: "你是一个代码审查助手",
  messages: [{ role: "user", content: "请审查以下代码..." }],
});
console.log(message.content[0].text);
```

国产模型的API大部分兼容OpenAI格式，换个base_url和api_key就行。比如调DeepSeek：

```python
client = OpenAI(
    api_key="your-deepseek-key",
    base_url="https://api.deepseek.com"
)
# 后面的调用方式跟OpenAI完全一样
```

## 三种调用模式

**同步调用**就是上面展示的方式，请求发出去，等模型生成完所有内容，一次性返回。简单直接，但问题是模型生成一段长文本可能要10-30秒，用户会看到一个漫长的loading。

**流式调用（Streaming）**才是生产环境的主流方式。模型每生成一个token就推送给你，前端逐字显示，用户体验好得多——就像ChatGPT那种逐字打出来的效果。

```python
# 流式调用
stream = client.chat.completions.create(
    model="gpt-4o",
    messages=[{"role": "user", "content": "写一首诗"}],
    stream=True
)
for chunk in stream:
    if chunk.choices[0].delta.content:
        print(chunk.choices[0].delta.content, end="", flush=True)
```

**函数调用（Function Calling / Tool Use）**是最强大也最重要的模式。它让模型不只是生成文本，还能"决定"调用你预定义的函数。比如用户问"北京今天天气怎么样"，模型会返回一个函数调用请求`get_weather(city="北京")`，你的代码执行这个函数拿到结果，再传回模型让它组织成自然语言回复。这个机制是后面Agent开发的基础，4.5节会详细展开。

## 深入理解Token

Token是LLM的"货币单位"，你必须理解它。

模型不是按字符处理文本的，而是先通过tokenizer把文本切分成token。中文大约每个字1-2个token，英文一个常见单词1个token，不常见的词可能被拆成多个。代码里的关键字通常是1个token，但变量名可能被拆开。

```
"Hello World" → ["Hello", " World"] → 2 tokens
"你好世界"   → ["你好", "世界"]    → 2 tokens (大约)
"function"   → ["function"]        → 1 token
"myVariableName" → ["my", "Variable", "Name"] → 3 tokens
```

计费逻辑是按输入token + 输出token分别计费的，输出token通常比输入贵2-4倍。以GPT-4o为例，输入大约$2.5/百万token，输出大约$10/百万token。看着便宜，但如果你的应用每天处理十万次请求，每次请求平均2000个token，那一个月下来就是好几千美金。

估算成本的公式很简单：

```
月成本 = 日请求量 × 平均输入token × 输入单价
       + 日请求量 × 平均输出token × 输出单价
       × 30
```

OpenAI和Anthropic都提供了tokenizer工具，开发前先用它估一下token量，不然上线之后看到账单会很惊喜（不是好的那种惊喜）。

## 速率限制与错误处理

所有模型API都有速率限制：每分钟请求数（RPM）和每分钟token数（TPM）。超过限制会返回429错误。你的代码必须处理这个。

一个靠谱的重试策略应该包含指数退避：

```python
import time
from openai import OpenAI, RateLimitError, APIError

client = OpenAI()

def call_with_retry(messages, max_retries=3):
    for attempt in range(max_retries):
        try:
            return client.chat.completions.create(
                model="gpt-4o",
                messages=messages
            )
        except RateLimitError:
            wait_time = 2 ** attempt  # 1s, 2s, 4s
            print(f"速率限制，{wait_time}秒后重试...")
            time.sleep(wait_time)
        except APIError as e:
            if e.status_code >= 500:  # 服务端错误才重试
                time.sleep(2 ** attempt)
            else:
                raise  # 客户端错误直接抛出
    raise Exception("重试次数用尽")
```

生产环境建议用专门的重试库（Python的`tenacity`，TypeScript的`p-retry`），不要自己手写循环。

## Prompt工程化

在ChatGPT里写prompt是手工活，但在代码里管理prompt是工程活。两者的差别就像在控制台写SQL和用ORM管理数据库的差别。

**System Prompt设计**是最关键的一环。一个好的system prompt应该明确角色定位、输出格式、行为边界：

```python
SYSTEM_PROMPT = """你是一个代码审查助手。你的职责是：

1. 检查代码中的潜在bug和安全漏洞
2. 指出不符合最佳实践的写法
3. 给出具体的修改建议，附上修改后的代码

输出格式要求：
- 每个问题用 [严重程度] 标注：🔴严重 🟡警告 🔵建议
- 先说问题，再给修改方案
- 如果代码没有问题，直接说"未发现问题"

注意事项：
- 只关注代码质量，不评论业务逻辑的合理性
- 不要重写整段代码，只给出需要修改的部分
- 使用与原代码相同的编程语言回复"""
```

**Prompt模板管理。** 当你的项目有几十个不同的prompt时，不要散落在各个文件里。统一放在一个目录或模块中管理，用变量替换动态内容：

````python
# prompts/code_review.py
REVIEW_TEMPLATE = """
请审查以下{language}代码：

文件路径：{file_path}
代码内容：
```{language}
{code}
````

项目使用的技术栈：{tech_stack}
重点关注：{focus_areas}
"""

def build_review_prompt(code, language, file_path, tech_stack, focus_areas):
return REVIEW_TEMPLATE.format(
code=code,
language=language,
file_path=file_path,
tech_stack=tech_stack,
focus_areas=", ".join(focus_areas)
)

```

Prompt也需要版本控制。当你修改了某个prompt让效果变好了，要能追溯改了什么。最简单的方式就是跟代码一起放在Git里；更正式一点可以用LangSmith之类的平台做prompt管理和A/B测试。

**Prompt评估。** 你怎么知道你的prompt好不好？不能靠感觉。准备一批测试用例（输入+期望输出），每次修改prompt后跑一遍，对比结果。这就是prompt的"单元测试"。后面AI工程化那节会详细讲评估方法。

这些基础打扎实了，后面做RAG、做Agent才不会到处踩坑。
```
